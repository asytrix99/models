{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95748ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy import log, max, exp, sum, clip\n",
    "from sklearn.preprocessing import PolynomialFeatures, OneHotEncoder\n",
    "\n",
    "# get pred_y, cost, grad (softmax)\n",
    "def multi_logistic_cost_gradient(X, W, Y, eps=1e-15):\n",
    "    z = X @ W\n",
    "    z_max = max(z, axis=1, keepdims=True)   \n",
    "    exp_z = exp(z - z_max)                   \n",
    "    pred_Y = exp_z / sum(exp_z, axis=1, keepdims=True)\n",
    "    pred_Y = clip(pred_Y, eps, 1 - eps)\n",
    "\n",
    "    cost   = sum(-(Y * log(pred_Y)))/ X.shape[0]\n",
    "    gradient = X.T @ (pred_Y-Y)/ X.shape[0]\n",
    "    return pred_Y, cost, gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "804316ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data\n",
    "\n",
    "X = np.array([[-1],[0],[0.5],[0.3],[0.8]])\n",
    "encoder = PolynomialFeatures(1)\n",
    "P = encoder.fit_transform(X)\n",
    "\n",
    "y = np.array([[1], [1], [2], [3], [2]])\n",
    "onehot_encoder=OneHotEncoder(sparse_output=False)\n",
    "Y = onehot_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b9f7569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Cost = 0.8022881819072072\n",
      "Initial Gradient = [[-0.03546935 -0.04792369  0.08339304]\n",
      " [ 0.13213239 -0.1401589   0.00802651]]\n",
      "Initial Weights = [[ 0.5  0.3  0.2]\n",
      " [-1.   0.5  0.1]]\n",
      "Iter 1 : cost = 0.7795683594693033\n",
      "Gradient = [[-0.03270099 -0.03511072  0.06781171]\n",
      " [ 0.12473711 -0.12981954  0.00508243]]\n",
      "Weights = [[ 0.51773468  0.32396185  0.15830348]\n",
      " [-1.0660662   0.57007945  0.09598675]]\n",
      "Iter 2 : cost = 0.7607300780934951\n",
      "Gradient = [[-0.03049513 -0.02461642  0.05511155]\n",
      " [ 0.11804638 -0.12085116  0.00280477]]\n",
      "Weights = [[ 0.53408517  0.3415172   0.12439763]\n",
      " [-1.12843475  0.63498922  0.09344553]]\n",
      "Iter 1000 : cost = 0.19604646547387247\n",
      "Iter 2000 : cost = 0.12921272181148719\n",
      "Iter 3000 : cost = 0.09584723302617415\n",
      "Iter 4000 : cost = 0.07568248180854417\n",
      "Iter 5000 : cost = 0.06225271831640409\n",
      "Iter 6000 : cost = 0.05271896343741894\n",
      "Iter 7000 : cost = 0.045629554089268366\n",
      "Iter 8000 : cost = 0.040167222553487494\n",
      "Iter 9000 : cost = 0.03583863738277689\n",
      "Iter 10000 : cost = 0.03232948005589925\n",
      "Final Cost = 0.03232948005589925\n",
      "Final Weights = [[  6.55403226  -8.56833681   3.01430455]\n",
      " [-25.60241504  27.13655968  -1.93414465]]\n"
     ]
    }
   ],
   "source": [
    "# learning\n",
    "learning_rate = 0.5\n",
    "W = np.array([[0.5, 0.3, 0.2], [-1, 0.5, 0.1]])\n",
    "\n",
    "pred_Y, cost, gradient = multi_logistic_cost_gradient(P, W, Y, eps=1e-15)\n",
    "print('Initial Cost =', cost)\n",
    "print('Initial Gradient =', gradient)\n",
    "print('Initial Weights =', W)\n",
    "\n",
    "num_iters = 10000\n",
    "cost_vec = np.zeros(num_iters+1)\n",
    "cost_vec[0] = cost\n",
    "\n",
    "for i in range(1, num_iters+1):\n",
    "\n",
    "    # update w\n",
    "    W = W - learning_rate*gradient\n",
    "\n",
    "    # compute updated cost and new gradient\n",
    "    pred_Y, cost, gradient = multi_logistic_cost_gradient(P, W, Y, eps=1e-15)\n",
    "    cost_vec[i] = cost\n",
    "\n",
    "    if(i % 1000 == 0):\n",
    "        print('Iter', i, ': cost =', cost)\n",
    "    if(i<3):\n",
    "        print('Iter', i, ': cost =', cost)\n",
    "        print('Gradient =', gradient)\n",
    "        print('Weights =', W)\n",
    "\n",
    "print('Final Cost =', cost)\n",
    "print('Final Weights =', W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d372ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction\n",
    "x_test = np.array([1,-0.1])\n",
    "\n",
    "z = x_test @ W\n",
    "Y_test = np.exp(z) / np.sum(np.exp(z), axis=-1, keepdims=True)\n",
    "print(\"z: \" + str(z))\n",
    "print(\"Y_test: \" + str(Y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aiml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
